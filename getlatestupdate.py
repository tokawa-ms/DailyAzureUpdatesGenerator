#!/usr/bin/env python3
"""
Azure Updates RSS ãƒ•ã‚£ãƒ¼ãƒ‰ã‚’èª­ã¿è¾¼ã¿ã€æŒ‡å®šæ™‚é–“å†…ã®æ›´æ–°ã‚’ Azure OpenAI ã§è¦ç´„ã™ã‚‹ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³

ç’°å¢ƒå¤‰æ•°:
- AOAI_ENDPOINT: Azure OpenAI ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
- AOAI_KEY: Azure OpenAI API ã‚­ãƒ¼
- DEPLOYMENT: Azure OpenAI ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆå
- API_VER: Azure OpenAI API ãƒãƒ¼ã‚¸ãƒ§ãƒ³
- CHECK_HOURS: ãƒã‚§ãƒƒã‚¯å¯¾è±¡æ™‚é–“ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 24æ™‚é–“ï¼‰
"""

import os
import sys
import logging
import argparse
from datetime import datetime, timedelta, timezone
from typing import List, Dict, Optional
import json
import time
import re
from urllib.parse import urlparse, parse_qs

# ã‚µãƒ¼ãƒ‰ãƒ‘ãƒ¼ãƒ†ã‚£ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import feedparser
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("azure_updates.log", encoding="utf-8"),
        logging.StreamHandler(sys.stdout),
    ],
)
logger = logging.getLogger(__name__)


class AzureOpenAIClient:
    """Azure OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""

    def __init__(self, endpoint: str, api_key: str, deployment: str, api_version: str):
        """
        Azure OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–

        Args:
            endpoint: Azure OpenAI ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
            api_key: API ã‚­ãƒ¼
            deployment: ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆå
            api_version: API ãƒãƒ¼ã‚¸ãƒ§ãƒ³
        """
        self.endpoint = endpoint.rstrip("/")
        self.api_key = api_key
        self.deployment = deployment
        self.api_version = api_version

        # HTTPã‚»ãƒƒã‚·ãƒ§ãƒ³ã®è¨­å®šï¼ˆãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãï¼‰
        self.session = requests.Session()
        retry_strategy = Retry(
            total=3,
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504],
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        self.session.mount("http://", adapter)
        self.session.mount("https://", adapter)

        # ãƒ˜ãƒƒãƒ€ãƒ¼è¨­å®š
        self.session.headers.update(
            {"Content-Type": "application/json", "api-key": self.api_key}
        )

        logger.info("Azure OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")

    def summarize_update(
        self,
        title: str,
        description: str,
        link: str,
        api_details: Optional[Dict] = None,
    ) -> Optional[str]:
        """
        Azure Update ã‚’æ—¥æœ¬èªã§è¦ç´„

        Args:
            title: ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã®ã‚¿ã‚¤ãƒˆãƒ«
            description: ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã®è©³ç´°
            link: ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã®ãƒªãƒ³ã‚¯
            api_details: API ã‹ã‚‰å–å¾—ã—ãŸè©³ç´°æƒ…å ±ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

        Returns:
            è¦ç´„ãƒ†ã‚­ã‚¹ãƒˆï¼ˆå¤±æ•—æ™‚ã¯Noneï¼‰
        """
        try:
            url = f"{self.endpoint}/openai/deployments/{self.deployment}/chat/completions?api-version={self.api_version}"

            # è©³ç´°ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯APIæƒ…å ±ã‚’ä½¿ç”¨
            content_source = "RSS"
            actual_title = title
            actual_content = description

            if api_details:
                content_source = "API"
                # APIã‹ã‚‰å–å¾—ã—ãŸã‚¿ã‚¤ãƒˆãƒ«ãŒã‚ã‚Œã°ä½¿ç”¨
                if api_details.get("api_title"):
                    actual_title = api_details["api_title"]

                # APIã‹ã‚‰å–å¾—ã—ãŸæœ¬æ–‡ãŒã‚ã‚Œã°ä½¿ç”¨
                if api_details.get("api_content"):
                    actual_content = api_details["api_content"]

                logger.info(
                    f"è¦ç´„å‡¦ç†ã§{content_source}æƒ…å ±ã‚’ä½¿ç”¨: {actual_title[:50]}..."
                )

            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
            prompt = f"""
ä»¥ä¸‹ã®Azure Updateã‚’æ—¥æœ¬èªã§ç°¡æ½”ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚æŠ€è¡“è€…å‘ã‘ã«é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’å«ã‚ã¦ãã ã•ã„ã€‚

ã‚¿ã‚¤ãƒˆãƒ«: {actual_title}

è©³ç´°: {actual_content}

ãƒªãƒ³ã‚¯: {link}

è¦ç´„ã¯ä»¥ä¸‹ã®å½¢å¼ã§ä½œæˆã—ã¦ãã ã•ã„ï¼š
- ä½•ãŒæ›´æ–°ã•ã‚ŒãŸã‹
- ä¸»ãªå¤‰æ›´ç‚¹ã‚„æ–°æ©Ÿèƒ½
- å½±éŸ¿ã‚’å—ã‘ã‚‹å¯¾è±¡
- æ³¨æ„ç‚¹ãŒã‚ã‚Œã°è¨˜è¼‰

200æ–‡å­—ç¨‹åº¦ã§ç°¡æ½”ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚

æƒ…å ±æº: {content_source}ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
"""

            payload = {
                "messages": [
                    {
                        "role": "system",
                        "content": "ã‚ãªãŸã¯Azureã®å°‚é–€å®¶ã§ã™ã€‚Azure Updateã®å†…å®¹ã‚’æŠ€è¡“è€…å‘ã‘ã«åˆ†ã‹ã‚Šã‚„ã™ãæ—¥æœ¬èªã§è¦ç´„ã—ã¾ã™ã€‚",
                    },
                    {"role": "user", "content": prompt},
                ],
                "max_tokens": 500,
                "temperature": 0.3,
                "top_p": 0.95,
            }

            response = self.session.post(url, json=payload, timeout=30)
            response.raise_for_status()

            result = response.json()

            if "choices" in result and len(result["choices"]) > 0:
                summary = result["choices"][0]["message"]["content"].strip()
                logger.info(f"è¦ç´„å®Œäº†({content_source}): {actual_title[:50]}...")
                return summary
            else:
                logger.error("äºˆæœŸã—ãªã„ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼ã‚’å—ä¿¡ã—ã¾ã—ãŸ")
                return None

        except requests.exceptions.RequestException as e:
            logger.error("API ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
            return None
        except Exception as e:
            logger.error("è¦ç´„å‡¦ç†ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
            return None

    def generate_detailed_summary(
        self, title: str, content: str, link: str
    ) -> Optional[str]:
        """
        è©³ç´°ãƒ¢ãƒ¼ãƒ‰ç”¨ã®è©³ç´°è¦ç´„ã‚’ç”Ÿæˆï¼ˆ500æ–‡å­—ä»¥å†…ï¼‰

        Args:
            title: ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã®ã‚¿ã‚¤ãƒˆãƒ«
            content: ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã®è©³ç´°å†…å®¹
            link: ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã®ãƒªãƒ³ã‚¯

        Returns:
            è©³ç´°è¦ç´„ãƒ†ã‚­ã‚¹ãƒˆï¼ˆå¤±æ•—æ™‚ã¯Noneï¼‰
        """
        try:
            url = f"{self.endpoint}/openai/deployments/{self.deployment}/chat/completions?api-version={self.api_version}"

            # è©³ç´°è¦ç´„ç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
            prompt = f"""
ä»¥ä¸‹ã®Azure Updateã«ã¤ã„ã¦ã€æŠ€è¡“è€…å‘ã‘ã«è©³ç´°ãªèª¬æ˜ã‚’æ—¥æœ¬èªã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
ã‚ãªãŸã¯ã€ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹å½¹å‰²ã‚’ä¸ãˆã‚‰ã‚Œã¦ã„ã¾ã™ã€‚æŒ‡ç¤ºã«å¯¾ã—ã¦äººé–“ãŒè¡Œã†ã‚ˆã†ãªè¿”ç­”ã¯ä¸è¦ã€‚æ·¡ã€…ã¨è©³ç´°ãªè¦ç´„æ–‡ç« ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ã‚¿ã‚¤ãƒˆãƒ«: {title}

è©³ç´°å†…å®¹: {content}

ãƒªãƒ³ã‚¯: {link}

ä»¥ä¸‹ã®è¦³ç‚¹ã‹ã‚‰è©³ç´°ã«èª¬æ˜ã—ã¦ãã ã•ã„ï¼š
- ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã®èƒŒæ™¯ã¨ç›®çš„
- å…·ä½“çš„ãªæ©Ÿèƒ½ã‚„å¤‰æ›´å†…å®¹ã®è©³ç´°
- æŠ€è¡“çš„ãªä»•çµ„ã¿ã‚„å®Ÿè£…æ–¹æ³•
- æ´»ç”¨ã‚·ãƒŠãƒªã‚ªã‚„ä½¿ç”¨ä¾‹
- æ³¨æ„ç‚¹ã‚„åˆ¶é™äº‹é …
- é–¢é€£ã™ã‚‹Azureã‚µãƒ¼ãƒ“ã‚¹ã¨ã®é€£æº

500æ–‡å­—ä»¥å†…ã§ã€æŠ€è¡“è€…ãŒå®Ÿéš›ã«æ´»ç”¨ã™ã‚‹éš›ã«å½¹ç«‹ã¤è©³ç´°æƒ…å ±ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚
"""

            payload = {
                "messages": [
                    {
                        "role": "system",
                        "content": "ã‚ãªãŸã¯Azureã®å°‚é–€å®¶ã§ã™ã€‚Azure Updateã®è©³ç´°ã‚’æŠ€è¡“è€…å‘ã‘ã«åˆ†ã‹ã‚Šã‚„ã™ãæ—¥æœ¬èªã§è§£èª¬ã—ã¾ã™ã€‚å®Ÿç”¨çš„ã§å…·ä½“çš„ãªæƒ…å ±ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚",
                    },
                    {"role": "user", "content": prompt},
                ],
                "max_tokens": 800,
                "temperature": 0.3,
                "top_p": 0.95,
            }

            response = self.session.post(url, json=payload, timeout=30)
            response.raise_for_status()

            result = response.json()

            if "choices" in result and len(result["choices"]) > 0:
                detailed_summary = result["choices"][0]["message"]["content"].strip()
                logger.info(f"è©³ç´°è¦ç´„å®Œäº†: {title[:50]}...")
                return detailed_summary
            else:
                logger.error("è©³ç´°è¦ç´„ã§äºˆæœŸã—ãªã„ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼ã‚’å—ä¿¡ã—ã¾ã—ãŸ")
                return None

        except requests.exceptions.RequestException as e:
            logger.error("è©³ç´°è¦ç´„ã®API ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
            return None
        except Exception as e:
            logger.error("è©³ç´°è¦ç´„å‡¦ç†ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
            return None

    def __del__(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        if hasattr(self, "session"):
            self.session.close()


class AzureUpdatesProcessor:
    """Azure Updates RSS ãƒ•ã‚£ãƒ¼ãƒ‰å‡¦ç†ã‚¯ãƒ©ã‚¹"""

    # Azure Updates ã®è¤‡æ•°ã®RSS URLã‚’è©¦è¡Œ
    RSS_URLS = [
        "https://www.microsoft.com/releasecommunications/api/v2/azure/rss",
        "https://azurecomcdn.azureedge.net/en-us/updates/feed/",
        "https://azure.microsoft.com/en-us/updates/feed/",
    ]

    # Azure Updates API ã®åŸºæœ¬URL
    AZURE_UPDATES_API_BASE = (
        "https://www.microsoft.com/releasecommunications/api/v2/azure/"
    )

    def __init__(
        self,
        openai_client: AzureOpenAIClient,
        check_hours: int = 24,
        details_mode: bool = False,
    ):
        """
        ãƒ—ãƒ­ã‚»ãƒƒã‚µã‚’åˆæœŸåŒ–

        Args:
            openai_client: Azure OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
            check_hours: ãƒã‚§ãƒƒã‚¯å¯¾è±¡æ™‚é–“ï¼ˆæ™‚é–“ï¼‰
            details_mode: è©³ç´°ãƒ¢ãƒ¼ãƒ‰ï¼ˆAPIã‹ã‚‰è©³ç´°æƒ…å ±ã‚’å–å¾—ï¼‰
        """
        self.openai_client = openai_client
        self.check_hours = check_hours
        self.details_mode = details_mode
        self.cutoff_time = datetime.now(timezone.utc) - timedelta(hours=check_hours)

        logger.info(f"ãƒã‚§ãƒƒã‚¯å¯¾è±¡æ™‚é–“: {check_hours}æ™‚é–“ä»¥å†…")
        logger.info(f"ã‚«ãƒƒãƒˆã‚ªãƒ•æ™‚é–“: {self.cutoff_time}")
        logger.info(f"è©³ç´°ãƒ¢ãƒ¼ãƒ‰: {'æœ‰åŠ¹' if details_mode else 'ç„¡åŠ¹'}")

        # APIã‚¢ã‚¯ã‚»ã‚¹ç”¨ã®HTTPã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’åˆæœŸåŒ–
        self.api_session = self._create_api_session()

    def _create_api_session(self) -> requests.Session:
        """
        Azure Updates API ã‚¢ã‚¯ã‚»ã‚¹ç”¨ã®HTTPã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ

        Returns:
            è¨­å®šæ¸ˆã¿ã®HTTPã‚»ãƒƒã‚·ãƒ§ãƒ³
        """
        session = requests.Session()

        # ãƒªãƒˆãƒ©ã‚¤æˆ¦ç•¥
        retry_strategy = Retry(
            total=3,
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504],
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("http://", adapter)
        session.mount("https://", adapter)

        # ãƒ–ãƒ©ã‚¦ã‚¶ã‚’å½è£…ã™ã‚‹ãƒ˜ãƒƒãƒ€ãƒ¼è¨­å®š
        session.headers.update(
            {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
                "Accept": "application/json, text/plain, */*",
                "Accept-Language": "ja,en-US;q=0.9,en;q=0.8",
                "Accept-Encoding": "gzip, deflate, br",
                "Connection": "keep-alive",
                "Cache-Control": "no-cache",
                "Pragma": "no-cache",
                "Referer": "https://azure.microsoft.com/",
                "Sec-Fetch-Dest": "empty",
                "Sec-Fetch-Mode": "cors",
                "Sec-Fetch-Site": "cross-site",
            }
        )

        logger.debug("Azure Updates APIç”¨HTTPã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
        return session

    def extract_update_id(self, link: str) -> Optional[str]:
        """
        Azure Updates ã®ãƒªãƒ³ã‚¯ã‹ã‚‰ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆIDã‚’æŠ½å‡º

        Args:
            link: Azure Updates ã®ãƒªãƒ³ã‚¯

        Returns:
            ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆIDï¼ˆæŠ½å‡ºã§ããªã„å ´åˆã¯Noneï¼‰
        """
        try:
            # URLã‚’ãƒ‘ãƒ¼ã‚¹
            parsed_url = urlparse(link)

            # ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‹ã‚‰ id ã‚’å–å¾—
            query_params = parse_qs(parsed_url.query)
            if "id" in query_params and query_params["id"]:
                update_id = query_params["id"][0]
                logger.debug(f"ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆIDæŠ½å‡ºæˆåŠŸ: {update_id} from {link}")
                return update_id

            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: URLãƒ‘ã‚¹ã‹ã‚‰æ•°å­—ã‚’æŠ½å‡º
            path_match = re.search(r"/(\d+)/?$", parsed_url.path)
            if path_match:
                update_id = path_match.group(1)
                logger.debug(f"ãƒ‘ã‚¹ã‹ã‚‰ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆIDæŠ½å‡º: {update_id} from {link}")
                return update_id

            logger.warning(f"ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆIDã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ: {link}")
            return None

        except Exception as e:
            logger.error(f"ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆIDæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {link} - {e}")
            return None

    def fetch_update_details(self, update_id: str) -> Optional[Dict]:
        """
        Azure Updates API ã‹ã‚‰è©³ç´°æƒ…å ±ã‚’å–å¾—

        Args:
            update_id: ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆID

        Returns:
            è©³ç´°æƒ…å ±è¾æ›¸ï¼ˆå–å¾—å¤±æ•—æ™‚ã¯Noneï¼‰
        """
        try:
            api_url = f"{self.AZURE_UPDATES_API_BASE}{update_id}"
            logger.info(f"APIè©³ç´°æƒ…å ±å–å¾—ä¸­: {api_url}")

            response = self.api_session.get(api_url, timeout=30)
            response.raise_for_status()

            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®è©³ç´°ã‚’ãƒ­ã‚°å‡ºåŠ›
            logger.debug(f"API HTTP ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {response.status_code}")
            logger.debug(
                f"API Content-Type: {response.headers.get('Content-Type', 'Unknown')}"
            )
            logger.debug(f"API ãƒ¬ã‚¹ãƒãƒ³ã‚¹é•·: {len(response.content)} bytes")

            # JSONã¨ã—ã¦è§£æ
            data = response.json()

            # ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºæƒ…å ±ã‚’è¨ˆç®—
            json_str = json.dumps(data, ensure_ascii=False) if data else "{}"
            char_count = len(json_str)
            byte_count = len(json_str.encode("utf-8"))

            logger.info(
                f"APIè©³ç´°æƒ…å ±å–å¾—æˆåŠŸ: {update_id} ({char_count}æ–‡å­—, {byte_count}ãƒã‚¤ãƒˆ)"
            )
            logger.debug(
                f"API ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹é€ : {list(data.keys()) if isinstance(data, dict) else type(data)}"
            )

            return data

        except requests.exceptions.RequestException as e:
            logger.error(
                f"APIè©³ç´°æƒ…å ±å–å¾—ã§HTTPã‚¨ãƒ©ãƒ¼: {update_id} - {type(e).__name__}: {e}"
            )
            return None
        except json.JSONDecodeError as e:
            logger.error(f"APIè©³ç´°æƒ…å ±ã®JSONè§£æã‚¨ãƒ©ãƒ¼: {update_id} - {e}")
            return None
        except Exception as e:
            logger.error(f"APIè©³ç´°æƒ…å ±å–å¾—ã§äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {update_id} - {e}")
            return None

    def enhance_update_with_details(self, update: Dict) -> Dict:
        """
        æ›´æ–°æƒ…å ±ã‚’è©³ç´°APIæƒ…å ±ã§æ‹¡å¼µ

        Args:
            update: åŸºæœ¬æ›´æ–°æƒ…å ±

        Returns:
            æ‹¡å¼µã•ã‚ŒãŸæ›´æ–°æƒ…å ±
        """
        if not self.details_mode:
            return update

        # ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆIDã‚’æŠ½å‡º
        update_id = self.extract_update_id(update.get("link", ""))
        if not update_id:
            logger.warning(
                f"è©³ç´°æƒ…å ±å–å¾—ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆIDãªã—ï¼‰: {update.get('title', 'Unknown')}"
            )
            return update

        # APIè©³ç´°æƒ…å ±ã‚’å–å¾—
        details = self.fetch_update_details(update_id)
        if not details:
            logger.warning(f"è©³ç´°æƒ…å ±å–å¾—å¤±æ•—: {update.get('title', 'Unknown')}")
            return update

        # è©³ç´°æƒ…å ±ã§æ›´æ–°ã‚’æ‹¡å¼µ
        enhanced_update = update.copy()
        enhanced_update["api_details"] = details
        enhanced_update["update_id"] = update_id

        # APIã‹ã‚‰å–å¾—ã—ãŸæƒ…å ±ã§æ—¢å­˜æƒ…å ±ã‚’ä¸Šæ›¸ã/æ‹¡å¼µ
        if isinstance(details, dict):
            # ã‚¿ã‚¤ãƒˆãƒ«ã®æ›´æ–°
            if "title" in details and details["title"]:
                enhanced_update["api_title"] = details["title"]
                logger.debug(f"APIã‚¿ã‚¤ãƒˆãƒ«å–å¾—: {details['title']}")

            # æœ¬æ–‡ã®æ›´æ–°
            if "content" in details and details["content"]:
                enhanced_update["api_content"] = details["content"]
                logger.debug(f"APIæœ¬æ–‡å–å¾—: {len(details['content'])} æ–‡å­—")

            # å…¬é–‹æ—¥ã®æ›´æ–°
            if "publishedDateTime" in details and details["publishedDateTime"]:
                enhanced_update["api_published"] = details["publishedDateTime"]
                logger.debug(f"APIå…¬é–‹æ—¥å–å¾—: {details['publishedDateTime']}")

            # ã‚«ãƒ†ã‚´ãƒªæƒ…å ±ã®æ›´æ–°
            if "categories" in details and details["categories"]:
                enhanced_update["api_categories"] = details["categories"]
                logger.debug(f"APIã‚«ãƒ†ã‚´ãƒªå–å¾—: {details['categories']}")

        logger.info(f"è©³ç´°æƒ…å ±ã§æ‹¡å¼µå®Œäº†: {update.get('title', 'Unknown')}")
        return enhanced_update

    def __del__(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        if hasattr(self, "api_session"):
            self.api_session.close()

    def fetch_rss_feed(self) -> Optional[feedparser.FeedParserDict]:
        """
        RSS ãƒ•ã‚£ãƒ¼ãƒ‰ã‚’å–å¾—ï¼ˆè¤‡æ•°URLã‚’è©¦è¡Œï¼‰

        Returns:
            ãƒ‘ãƒ¼ã‚¹ã•ã‚ŒãŸãƒ•ã‚£ãƒ¼ãƒ‰ï¼ˆå¤±æ•—æ™‚ã¯Noneï¼‰
        """
        for url in self.RSS_URLS:
            try:
                logger.info("RSSãƒ•ã‚£ãƒ¼ãƒ‰ã‚’å–å¾—ä¸­")

                # HTTPã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’è¨­å®šã—ã¦ã‚ˆã‚Šå …ç‰¢ã«ãƒ•ã‚£ãƒ¼ãƒ‰ã‚’å–å¾—
                session = requests.Session()
                retry_strategy = Retry(
                    total=2,
                    backoff_factor=1,
                    status_forcelist=[429, 500, 502, 503, 504],
                )
                adapter = HTTPAdapter(max_retries=retry_strategy)
                session.mount("http://", adapter)
                session.mount("https://", adapter)

                # ãƒ˜ãƒƒãƒ€ãƒ¼è¨­å®š
                headers = {
                    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
                    "Accept": "application/rss+xml, application/xml, text/xml, */*",
                    "Accept-Language": "ja,en-US;q=0.9,en;q=0.8",
                    "Accept-Encoding": "gzip, deflate, br",
                    "Connection": "keep-alive",
                    "Cache-Control": "no-cache",
                }

                # ãƒ•ã‚£ãƒ¼ãƒ‰ã‚’HTTPã‚»ãƒƒã‚·ãƒ§ãƒ³çµŒç”±ã§å–å¾—
                feed = None
                try:
                    response = session.get(url, headers=headers, timeout=30)
                    response.raise_for_status()

                    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å†…å®¹ã‚’ãƒ­ã‚°å‡ºåŠ›ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
                    logger.debug(f"HTTP ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {response.status_code}")
                    logger.debug(
                        f"Content-Type: {response.headers.get('Content-Type', 'Unknown')}"
                    )
                    logger.debug(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹é•·: {len(response.content)} bytes")

                    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒç©ºã§ãªã„ã‹ãƒã‚§ãƒƒã‚¯
                    if not response.content:
                        logger.warning("RSSãƒ•ã‚£ãƒ¼ãƒ‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒç©ºã§ã™")
                        continue

                    # æ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’æ¤œå‡ºãƒ»ãƒ‡ã‚³ãƒ¼ãƒ‰
                    content_bytes = response.content
                    logger.debug(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹æœ€åˆã®100ãƒã‚¤ãƒˆ: {content_bytes[:100]}")

                    # ã¾ãšContent-Typeãƒ˜ãƒƒãƒ€ãƒ¼ã‹ã‚‰ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ç¢ºèª
                    content_type = response.headers.get("Content-Type", "")
                    encoding = "utf-8"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

                    if "charset=" in content_type:
                        try:
                            encoding = (
                                content_type.split("charset=")[1].split(";")[0].strip()
                            )
                            logger.debug(
                                f"Content-Typeã‹ã‚‰æ¤œå‡ºã•ã‚ŒãŸã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°: {encoding}"
                            )
                        except:
                            logger.debug(
                                "Content-Typeã‹ã‚‰ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ¤œå‡ºå¤±æ•—ã€UTF-8ã‚’ä½¿ç”¨"
                            )

                    # è¤‡æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è©¦è¡Œï¼ˆBOMå¯¾å¿œã‚’å„ªå…ˆï¼‰
                    content_str = None
                    tried_encodings = [
                        "utf-8-sig",
                        encoding,
                        "utf-8",
                        "latin1",
                        "cp1252",
                    ]

                    for enc in tried_encodings:
                        try:
                            content_str = content_bytes.decode(enc)
                            logger.debug(f"ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° '{enc}' ã§ãƒ‡ã‚³ãƒ¼ãƒ‰æˆåŠŸ")
                            break
                        except UnicodeDecodeError as e:
                            logger.debug(
                                f"ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° '{enc}' ã§ãƒ‡ã‚³ãƒ¼ãƒ‰å¤±æ•—: {e}"
                            )
                            continue

                    if content_str is None:
                        # æœ€å¾Œã®æ‰‹æ®µï¼šã‚¨ãƒ©ãƒ¼ã‚’ç„¡è¦–ã—ã¦ãƒ‡ã‚³ãƒ¼ãƒ‰
                        content_str = content_bytes.decode("utf-8", errors="replace")
                        logger.warning(
                            "ã™ã¹ã¦ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãŒå¤±æ•—ã€ã‚¨ãƒ©ãƒ¼ç„¡è¦–ã§ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã¾ã—ãŸ"
                        )

                    content_stripped = content_str.strip()

                    # BOMï¼ˆByte Order Markï¼‰ã‚’é™¤å»
                    if content_stripped.startswith("\ufeff"):
                        content_stripped = content_stripped[1:]
                        logger.debug("UTF-8 BOM ã‚’æ¤œå‡ºãƒ»é™¤å»ã—ã¾ã—ãŸ")

                    # ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å…ˆé ­ã‚’è©³ã—ãç¢ºèª
                    logger.debug(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹å…ˆé ­50æ–‡å­—: '{content_stripped[:50]}'")
                    logger.debug(
                        f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹å…ˆé ­ã®ãƒã‚¤ãƒˆè¡¨ç¾: {content_stripped[:50].encode('unicode_escape')}"
                    )

                    # å„æ¡ä»¶ã‚’å€‹åˆ¥ã«ãƒã‚§ãƒƒã‚¯ã—ã¦ãƒ­ã‚°å‡ºåŠ›
                    starts_with_xml_header = content_stripped.startswith("<?xml")
                    starts_with_rss = content_stripped.startswith("<rss")
                    starts_with_feed = content_stripped.startswith("<feed")
                    starts_with_angle = content_stripped.startswith("<")

                    logger.debug(f"XMLå¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯çµæœ:")
                    logger.debug(
                        f"  - XMLãƒ˜ãƒƒãƒ€ãƒ¼ ('<?xml') ã§é–‹å§‹: {starts_with_xml_header}"
                    )
                    logger.debug(f"  - RSSã‚¿ã‚° ('<rss') ã§é–‹å§‹: {starts_with_rss}")
                    logger.debug(f"  - Feedã‚¿ã‚° ('<feed') ã§é–‹å§‹: {starts_with_feed}")
                    logger.debug(f"  - ä»»æ„ã®ã‚¿ã‚° ('<') ã§é–‹å§‹: {starts_with_angle}")

                    # XMLã¨ã—ã¦å¦¥å½“ãã†ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆã‚ˆã‚Šå¯›å®¹ã«ï¼‰
                    is_xml_like = (
                        starts_with_xml_header
                        or starts_with_rss
                        or starts_with_feed
                        or starts_with_angle
                    )

                    logger.debug(f"æœ€çµ‚åˆ¤å®š is_xml_like: {is_xml_like}")

                    if not is_xml_like:
                        logger.warning("XMLã§ã¯ãªã„ãƒ¬ã‚¹ãƒãƒ³ã‚¹")
                        logger.warning(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹å…ˆé ­200æ–‡å­—: {content_str[:200]}")
                        logger.warning(
                            f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹å…ˆé ­ã®ãƒã‚¤ãƒˆ: {content_str[:50].encode('unicode_escape')}"
                        )
                        continue

                    logger.info(f"XMLãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆç¢ºèªOK: {content_stripped[:100]}...")

                    # feedparser ã§ãƒ‘ãƒ¼ã‚¹
                    logger.debug("feedparser ã«ã‚ˆã‚‹ãƒ‘ãƒ¼ã‚¹é–‹å§‹...")
                    feed = feedparser.parse(response.content)
                    logger.debug(
                        f"feedparser ãƒ‘ãƒ¼ã‚¹å®Œäº†: bozo={getattr(feed, 'bozo', 'Unknown')}"
                    )

                except requests.exceptions.RequestException as e:
                    logger.warning(f"HTTP ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {type(e).__name__}")
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: feedparser ã®ç›´æ¥å–å¾—ã‚’è©¦è¡Œ
                    logger.info("ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: feedparser ã§ã®ç›´æ¥å–å¾—ã‚’è©¦è¡Œ")
                    feed = feedparser.parse(url)
                    logger.debug("ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ feedparser ãƒ‘ãƒ¼ã‚¹å®Œäº†")

                finally:
                    session.close()

                # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ‘ãƒ¼ã‚¹çµæœã‚’ãƒã‚§ãƒƒã‚¯
                logger.debug(
                    f"ãƒ•ã‚£ãƒ¼ãƒ‰ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆç¢ºèª: {type(feed)} - hasattr(feed, 'entries'): {hasattr(feed, 'entries')}"
                )

                if not feed:
                    logger.warning("ãƒ•ã‚£ãƒ¼ãƒ‰ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                    continue

                # ã‚¨ãƒ³ãƒˆãƒªã®å­˜åœ¨ã‚’ã¾ãšç¢ºèª
                has_entries = hasattr(feed, "entries") and len(feed.entries) > 0
                logger.debug(
                    f"ã‚¨ãƒ³ãƒˆãƒªç¢ºèª: has_entries={has_entries}, ã‚¨ãƒ³ãƒˆãƒªæ•°={len(feed.entries) if hasattr(feed, 'entries') else 'N/A'}"
                )

                if feed.bozo:
                    logger.debug(
                        f"ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ‘ãƒ¼ã‚¹ã§è»½å¾®ãªè­¦å‘Š ({url}): {feed.bozo_exception}"
                    )

                    # ã‚¨ãƒ³ãƒˆãƒªãŒã‚ã‚Œã°è­¦å‘ŠãŒã‚ã£ã¦ã‚‚å‡¦ç†ç¶šè¡Œ
                    if has_entries:
                        logger.info(
                            f"ãƒ‘ãƒ¼ã‚¹è­¦å‘ŠãŒã‚ã‚Šã¾ã™ãŒã€{len(feed.entries)}ä»¶ã®ã‚¨ãƒ³ãƒˆãƒªãŒå–å¾—ã§ããŸãŸã‚å‡¦ç†ã‚’ç¶šè¡Œã—ã¾ã™"
                        )
                    else:
                        logger.warning(
                            f"ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã§ã‚¨ãƒ³ãƒˆãƒªãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ: {url}"
                        )
                        continue

                if not has_entries:
                    logger.warning("ãƒ•ã‚£ãƒ¼ãƒ‰ã«ã‚¨ãƒ³ãƒˆãƒªãŒã‚ã‚Šã¾ã›ã‚“")
                    continue

                logger.info(
                    f"ãƒ•ã‚£ãƒ¼ãƒ‰ã‚’å–å¾—å®Œäº†: {len(feed.entries)}ä»¶ã®ã‚¨ãƒ³ãƒˆãƒª ({url})"
                )

                # ãƒ•ã‚£ãƒ¼ãƒ‰ã®åŸºæœ¬æƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›
                if hasattr(feed, "feed"):
                    feed_info = feed.feed
                    logger.debug(
                        f"ãƒ•ã‚£ãƒ¼ãƒ‰ã‚¿ã‚¤ãƒˆãƒ«: {feed_info.get('title', 'Unknown')}"
                    )
                    logger.debug(
                        f"ãƒ•ã‚£ãƒ¼ãƒ‰èª¬æ˜: {feed_info.get('description', 'Unknown')}"
                    )
                    logger.debug(f"æœ€çµ‚æ›´æ–°: {feed_info.get('updated', 'Unknown')}")

                return feed

            except Exception as e:
                logger.warning(f"ãƒ•ã‚£ãƒ¼ãƒ‰å–å¾—ã‚¨ãƒ©ãƒ¼: {type(e).__name__}")
                continue

        # ã™ã¹ã¦ã®URLã§å¤±æ•—ã—ãŸå ´åˆ
        logger.error("ã™ã¹ã¦ã®RSS URLã§ãƒ•ã‚£ãƒ¼ãƒ‰å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return None

    def parse_date(self, date_str: str) -> Optional[datetime]:
        """
        æ—¥ä»˜æ–‡å­—åˆ—ã‚’ãƒ‘ãƒ¼ã‚¹ï¼ˆè¤‡æ•°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¯¾å¿œï¼‰

        Args:
            date_str: æ—¥ä»˜æ–‡å­—åˆ—

        Returns:
            datetime ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆå¤±æ•—æ™‚ã¯Noneï¼‰
        """
        if not date_str:
            return None

        try:
            # ã¾ãš feedparser ã®æ¨™æº–ãƒ‘ãƒ¼ã‚µãƒ¼ã‚’è©¦è¡Œ
            time_struct = feedparser._parse_date(date_str)
            if time_struct:
                return datetime(*time_struct[:6], tzinfo=timezone.utc)
        except Exception as e:
            logger.debug(f"feedparser ã«ã‚ˆã‚‹æ—¥ä»˜ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {date_str} - {e}")

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ä¸€èˆ¬çš„ãªæ—¥ä»˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’è©¦è¡Œ
        date_formats = [
            "%Y-%m-%dT%H:%M:%S.%fZ",
            "%Y-%m-%dT%H:%M:%SZ",
            "%Y-%m-%dT%H:%M:%S",
            "%Y-%m-%d %H:%M:%S",
            "%a, %d %b %Y %H:%M:%S %z",
            "%a, %d %b %Y %H:%M:%S GMT",
            "%Y-%m-%dT%H:%M:%S%z",
        ]

        for fmt in date_formats:
            try:
                # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³æƒ…å ±ãŒãªã„å ´åˆã¯UTCã¨ã—ã¦æ‰±ã†
                if "%z" in fmt:
                    parsed_dt = datetime.strptime(date_str, fmt)
                else:
                    parsed_dt = datetime.strptime(date_str, fmt).replace(
                        tzinfo=timezone.utc
                    )
                return parsed_dt
            except ValueError:
                continue

        logger.debug(f"ã™ã¹ã¦ã®æ—¥ä»˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§è§£æã«å¤±æ•—: {date_str}")
        return None

    def filter_recent_updates(self, feed: feedparser.FeedParserDict) -> List[Dict]:
        """
        æŒ‡å®šæ™‚é–“å†…ã®æ›´æ–°ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°

        Args:
            feed: ãƒ‘ãƒ¼ã‚¹ã•ã‚ŒãŸãƒ•ã‚£ãƒ¼ãƒ‰

        Returns:
            ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸæ›´æ–°ãƒªã‚¹ãƒˆ
        """
        recent_updates = []

        for entry in feed.entries:
            # å…¬é–‹æ—¥æ™‚ã‚’å–å¾—ï¼ˆAzure Updates ã§ã¯ a10:updated ã‚’å„ªå…ˆï¼‰
            published_date = None

            # 1. ã¾ãš a10:updated ã‚’ç¢ºèªï¼ˆAzure Updates ã®å®Ÿéš›ã®æ›´æ–°æ—¥æ™‚ï¼‰
            if hasattr(entry, "updated"):
                published_date = self.parse_date(entry.updated)
                logger.debug(
                    f"a10:updated ã‹ã‚‰æ—¥ä»˜å–å¾—: {entry.updated} -> {published_date}"
                )

            # 2. ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: published ã‚’ç¢ºèª
            if not published_date and hasattr(entry, "published"):
                published_date = self.parse_date(entry.published)
                logger.debug(
                    f"published ã‹ã‚‰æ—¥ä»˜å–å¾—: {entry.published} -> {published_date}"
                )

            # 3. æœ€å¾Œã®æ‰‹æ®µ: updated_parsed ã‚’ç¢ºèª
            if (
                not published_date
                and hasattr(entry, "updated_parsed")
                and entry.updated_parsed
            ):
                try:
                    published_date = datetime(
                        *entry.updated_parsed[:6], tzinfo=timezone.utc
                    )
                    logger.debug(
                        f"updated_parsed ã‹ã‚‰æ—¥ä»˜å–å¾—: {entry.updated_parsed} -> {published_date}"
                    )
                except Exception as e:
                    logger.debug(f"updated_parsed ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")

            if not published_date:
                logger.debug(
                    f"æ—¥ä»˜ãŒå–å¾—ã§ããªã„ã‚¨ãƒ³ãƒˆãƒªã‚’ã‚¹ã‚­ãƒƒãƒ—: {entry.get('title', 'Unknown')}"
                )
                continue

            # æŒ‡å®šæ™‚é–“å†…ã‹ãƒã‚§ãƒƒã‚¯
            if published_date >= self.cutoff_time:
                update_info = {
                    "title": entry.get("title", ""),
                    "description": entry.get("description", ""),
                    "link": entry.get("link", ""),
                    "published": published_date,
                    "categories": [
                        tag.get("term", "") for tag in entry.get("tags", [])
                    ],
                }

                # è©³ç´°ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯è©³ç´°æƒ…å ±ã‚’å–å¾—
                if self.details_mode:
                    update_info = self.enhance_update_with_details(update_info)

                recent_updates.append(update_info)
                logger.info(f"å¯¾è±¡æ›´æ–°ã‚’ç™ºè¦‹: {update_info['title']}")

        logger.info(f"{len(recent_updates)}ä»¶ã®æœ€æ–°æ›´æ–°ã‚’ç™ºè¦‹")
        return recent_updates

    def process_updates(self) -> List[Dict]:
        """
        æ›´æ–°ã‚’å‡¦ç†ã—ã¦è¦ç´„ã‚’ç”Ÿæˆ

        Returns:
            è¦ç´„ä»˜ãæ›´æ–°ãƒªã‚¹ãƒˆ
        """
        # RSS ãƒ•ã‚£ãƒ¼ãƒ‰å–å¾—
        feed = self.fetch_rss_feed()
        if not feed:
            return []

        # æœ€æ–°æ›´æ–°ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        recent_updates = self.filter_recent_updates(feed)
        if not recent_updates:
            logger.info("æŒ‡å®šæ™‚é–“å†…ã«æ–°ã—ã„æ›´æ–°ã¯ã‚ã‚Šã¾ã›ã‚“")
            return []

        # å„æ›´æ–°ã‚’è¦ç´„
        processed_updates = []
        for i, update in enumerate(recent_updates, 1):
            logger.info(f"æ›´æ–°ã‚’å‡¦ç†ä¸­ ({i}/{len(recent_updates)}): {update['title']}")

            # APIãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’è€ƒæ…®ã—ã¦å°‘ã—å¾…æ©Ÿ
            if i > 1:
                time.sleep(1)

            # è¦ç´„ç”Ÿæˆï¼ˆè©³ç´°ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯APIè©³ç´°æƒ…å ±ã‚’ä½¿ç”¨ï¼‰
            api_details = (
                update if self.details_mode and update.get("api_details") else None
            )
            summary = self.openai_client.summarize_update(
                update["title"], update["description"], update["link"], api_details
            )

            update["summary"] = summary

            # è©³ç´°ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯è©³ç´°è¦ç´„ã‚‚ç”Ÿæˆ
            if self.details_mode:
                # APIãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’è€ƒæ…®ã—ã¦è¿½åŠ å¾…æ©Ÿ
                time.sleep(1)

                # è©³ç´°è¦ç´„ç”¨ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ±ºå®šï¼ˆAPIæƒ…å ±ã‚’å„ªå…ˆï¼‰
                detail_title = update.get("api_title", update["title"])
                detail_content = update.get("api_content", update["description"])

                detailed_summary = self.openai_client.generate_detailed_summary(
                    detail_title, detail_content, update["link"]
                )
                update["detailed_summary"] = detailed_summary

                if detailed_summary:
                    logger.info(f"è©³ç´°è¦ç´„ç”Ÿæˆå®Œäº†: {update['title'][:50]}...")
                else:
                    logger.warning(f"è©³ç´°è¦ç´„ç”Ÿæˆå¤±æ•—: {update['title'][:50]}...")

            processed_updates.append(update)

            if summary:
                mode_info = "è©³ç´°ãƒ¢ãƒ¼ãƒ‰" if self.details_mode else "æ¨™æº–ãƒ¢ãƒ¼ãƒ‰"
                logger.info(f"è¦ç´„ç”Ÿæˆå®Œäº†({mode_info}): {update['title'][:50]}...")
            else:
                logger.warning(f"è¦ç´„ç”Ÿæˆå¤±æ•—: {update['title'][:50]}...")

        return processed_updates

    def generate_markdown_report(self, updates: List[Dict]) -> str:
        """
        ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ

        Args:
            updates: å‡¦ç†æ¸ˆã¿æ›´æ–°ãƒªã‚¹ãƒˆ

        Returns:
            ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼ã®ãƒ¬ãƒãƒ¼ãƒˆ
        """
        today = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
        mode_text = "è©³ç´°ãƒ¢ãƒ¼ãƒ‰" if self.details_mode else "æ¨™æº–ãƒ¢ãƒ¼ãƒ‰"
        report_lines = [
            f"# {today} - Azure Updates è¦ç´„ãƒ¬ãƒãƒ¼ãƒˆ ({mode_text})",
            f"",
            f"**ç”Ÿæˆæ—¥æ™‚**: {today}",
            f"**å¯¾è±¡æœŸé–“**: éå» {self.check_hours} æ™‚é–“ä»¥å†…",
            f"**å‡¦ç†ãƒ¢ãƒ¼ãƒ‰**: {mode_text}",
            f"**æ›´æ–°ä»¶æ•°**: {len(updates)} ä»¶",
            f"",
        ]

        if not updates:
            report_lines.extend(
                [
                    "## çµæœ",
                    "",
                    "æœ¬æ—¥ã®æ›´æ–°ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚",
                    "",
                ]
            )
        else:
            report_lines.extend(["## æ›´æ–°ä¸€è¦§", ""])

            for i, update in enumerate(updates, 1):
                # è¡¨ç¤ºç”¨ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’æ±ºå®šï¼ˆè©³ç´°ãƒ¢ãƒ¼ãƒ‰ã§ã¯APIæƒ…å ±ã‚’å„ªå…ˆï¼‰
                display_title = update["title"]
                if self.details_mode and update.get("api_title"):
                    display_title = update["api_title"]

                report_lines.extend(
                    [
                        f"### {i}. {display_title}",
                        "",
                        f"**å…¬é–‹æ—¥æ™‚**: {update['published'].strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S UTC')}",
                        f"**ãƒªãƒ³ã‚¯**: [{display_title}]({update['link']})",
                        "",
                    ]
                )

                # è©³ç´°ãƒ¢ãƒ¼ãƒ‰æƒ…å ±ã®è¡¨ç¤º
                if self.details_mode and update.get("update_id"):
                    report_lines.extend(
                        [
                            f"**ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆID**: {update['update_id']}",
                            f"**æƒ…å ±æº**: Azure Updates API",
                            "",
                        ]
                    )

                # ã‚«ãƒ†ã‚´ãƒªæƒ…å ±ï¼ˆè©³ç´°ãƒ¢ãƒ¼ãƒ‰ã§ã¯APIæƒ…å ±ã‚’å„ªå…ˆï¼‰
                categories = update["categories"]
                if self.details_mode and update.get("api_categories"):
                    categories = update["api_categories"]

                if categories:
                    categories_str = (
                        ", ".join(categories)
                        if isinstance(categories, list)
                        else str(categories)
                    )
                    report_lines.extend([f"**ã‚«ãƒ†ã‚´ãƒª**: {categories_str}", ""])

                if update.get("summary"):
                    report_lines.extend(["**è¦ç´„**:", "", update["summary"], ""])
                else:
                    report_lines.extend(["**è¦ç´„**: ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ", ""])

                # è©³ç´°å†…å®¹ï¼ˆè©³ç´°ãƒ¢ãƒ¼ãƒ‰ã§ã¯GPTè©³ç´°è¦ç´„ã€æ¨™æº–ãƒ¢ãƒ¼ãƒ‰ã§ã¯API/RSSæƒ…å ±ï¼‰
                if self.details_mode and update.get("detailed_summary"):
                    # è©³ç´°ãƒ¢ãƒ¼ãƒ‰ï¼šGPTç”Ÿæˆã®è©³ç´°è¦ç´„ã‚’ä½¿ç”¨
                    report_lines.extend(
                        ["**è©³ç´°**:", "", update["detailed_summary"], "", "---", ""]
                    )
                else:
                    # æ¨™æº–ãƒ¢ãƒ¼ãƒ‰ï¼šAPIæƒ…å ±ã¾ãŸã¯RSSæƒ…å ±ã‚’ä½¿ç”¨
                    detail_content = update["description"]
                    if self.details_mode and update.get("api_content"):
                        detail_content = update["api_content"]
                    report_lines.extend(
                        ["**è©³ç´°**:", "", detail_content, "", "---", ""]
                    )

        report_lines.extend(
            [
                "",
                f"*ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯è‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸ - {datetime.now(timezone(timedelta(hours=9))).strftime('%Y-%m-%d %H:%M:%S JST')}*",
            ]
        )

        return "\n".join(report_lines)

    def save_report(self, content: str, output_dir: str = "updates") -> str:
        """
        ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜

        Args:
            content: ãƒ¬ãƒãƒ¼ãƒˆå†…å®¹
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª

        Returns:
            ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        os.makedirs(output_dir, exist_ok=True)

        # ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆï¼ˆæœ¬æ—¥ã®æ—¥ä»˜ï¼‰
        today = datetime.now().strftime("%Y-%m-%d")
        filename = f"azure-updates-{today}.md"
        filepath = os.path.join(output_dir, filename)

        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        try:
            with open(filepath, "w", encoding="utf-8") as f:
                f.write(content)
            logger.info(f"ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filepath}")
            return filepath
        except Exception as e:
            logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            raise


def load_config() -> Dict[str, str]:
    """
    ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã¿

    Returns:
        è¨­å®šè¾æ›¸
    """
    config = {
        "endpoint": os.getenv("AOAI_ENDPOINT"),
        "api_key": os.getenv("AOAI_KEY"),
        "deployment": os.getenv("DEPLOYMENT"),
        "api_version": os.getenv("API_VER", "2025-01-01-preview"),
        "check_hours": int(os.getenv("CHECK_HOURS", "24")),
    }

    # å¿…é ˆè¨­å®šã®æ¤œè¨¼
    required_vars = ["endpoint", "api_key", "deployment"]
    missing_vars = [var for var in required_vars if not config[var]]

    if missing_vars:
        logger.error(
            f"å¿…é ˆç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“: {', '.join([var.upper() for var in missing_vars])}"
        )
        sys.exit(1)

    logger.info("è¨­å®šã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    return config


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(description="Azure Updates RSS ãƒ•ã‚£ãƒ¼ãƒ‰å‡¦ç†")
    parser.add_argument(
        "--hours",
        type=int,
        help="ãƒã‚§ãƒƒã‚¯å¯¾è±¡æ™‚é–“ï¼ˆæ™‚é–“ï¼‰ã€‚ç’°å¢ƒå¤‰æ•° CHECK_HOURS ã‚ˆã‚Šå„ªå…ˆã•ã‚Œã¾ã™",
    )
    parser.add_argument(
        "--output-dir",
        default="updates",
        help="å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: updatesï¼‰",
    )
    parser.add_argument("--verbose", action="store_true", help="è©³ç´°ãƒ­ã‚°ã‚’å‡ºåŠ›")
    parser.add_argument(
        "--test-feed", action="store_true", help="RSSãƒ•ã‚£ãƒ¼ãƒ‰ã®ãƒ†ã‚¹ãƒˆå–å¾—ã®ã¿å®Ÿè¡Œ"
    )
    parser.add_argument(
        "--details",
        action="store_true",
        help="è©³ç´°ãƒ¢ãƒ¼ãƒ‰: Azure Updates APIã‹ã‚‰è©³ç´°æƒ…å ±ã‚’å–å¾—",
    )

    args = parser.parse_args()

    # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«è¨­å®š
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    try:
        # ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã®å ´åˆ
        if args.test_feed:
            logger.info("RSSãƒ•ã‚£ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œä¸­...")
            processor = AzureUpdatesProcessor(
                None, 24, False
            )  # OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãªã—ã€è©³ç´°ãƒ¢ãƒ¼ãƒ‰ç„¡åŠ¹
            feed = processor.fetch_rss_feed()
            if feed:
                print(f"\nâœ… ãƒ•ã‚£ãƒ¼ãƒ‰å–å¾—æˆåŠŸ!")
                print(f"ğŸ“Š ã‚¨ãƒ³ãƒˆãƒªæ•°: {len(feed.entries)} ä»¶")

                # ãƒ•ã‚£ãƒ¼ãƒ‰æƒ…å ±è¡¨ç¤º
                if hasattr(feed, "feed"):
                    feed_info = feed.feed
                    print(f"ğŸ“° ãƒ•ã‚£ãƒ¼ãƒ‰ã‚¿ã‚¤ãƒˆãƒ«: {feed_info.get('title', 'Unknown')}")
                    print(
                        f"ğŸ“ ãƒ•ã‚£ãƒ¼ãƒ‰èª¬æ˜: {feed_info.get('description', 'Unknown')[:100]}..."
                    )

                if len(feed.entries) > 0:
                    print(f"\nğŸ“‹ æœ€æ–°ã‚¨ãƒ³ãƒˆãƒªä¾‹ï¼ˆæœ€å¤§5ä»¶ï¼‰:")
                    for i, entry in enumerate(feed.entries[:5], 1):
                        title = entry.get("title", "No Title")
                        # Azure Updates ã§ã¯ updated ã‚’å„ªå…ˆ
                        updated = entry.get(
                            "updated", entry.get("published", "No Date")
                        )
                        link = entry.get("link", "No Link")

                        print(f"  {i}. {title[:80]}...")
                        print(f"     ğŸ“… æ›´æ–°æ—¥: {updated}")
                        print(f"     ğŸ”— ãƒªãƒ³ã‚¯: {link}")

                        # ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆIDæŠ½å‡ºãƒ†ã‚¹ãƒˆ
                        update_id = processor.extract_update_id(link)
                        if update_id:
                            print(f"     ğŸ†” ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆID: {update_id}")
                        else:
                            print(f"     âŒ ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆIDæŠ½å‡ºå¤±æ•—")

                        # æ—¥ä»˜ãƒ‘ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ
                        parsed_date = processor.parse_date(updated)
                        if parsed_date:
                            print(f"     âœ… æ—¥ä»˜ãƒ‘ãƒ¼ã‚¹æˆåŠŸ: {parsed_date}")
                        else:
                            print(f"     âŒ æ—¥ä»˜ãƒ‘ãƒ¼ã‚¹å¤±æ•—")
                        print()

                print(f"ğŸ‰ ãƒ†ã‚¹ãƒˆå®Œäº†: RSSãƒ•ã‚£ãƒ¼ãƒ‰ã¯æ­£å¸¸ã«å–å¾—ãƒ»ãƒ‘ãƒ¼ã‚¹ã§ãã¦ã„ã¾ã™")
            else:
                print("\nâŒ ãƒ•ã‚£ãƒ¼ãƒ‰å–å¾—å¤±æ•—")
                print("ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ« azure_updates.log ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
            return

        # è¨­å®šèª­ã¿è¾¼ã¿
        config = load_config()

        # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã§æ™‚é–“ã‚’ä¸Šæ›¸ã
        if args.hours:
            config["check_hours"] = args.hours

        # Azure OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
        openai_client = AzureOpenAIClient(
            endpoint=config["endpoint"],
            api_key=config["api_key"],
            deployment=config["deployment"],
            api_version=config["api_version"],
        )

        # Azure Updates ãƒ—ãƒ­ã‚»ãƒƒã‚µåˆæœŸåŒ–
        processor = AzureUpdatesProcessor(
            openai_client=openai_client,
            check_hours=config["check_hours"],
            details_mode=args.details,
        )

        # æ›´æ–°å‡¦ç†
        logger.info("Azure Updates ã®å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™")
        updates = processor.process_updates()

        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        logger.info("ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­")
        report_content = processor.generate_markdown_report(updates)

        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        output_path = processor.save_report(report_content, args.output_dir)

        # çµæœè¡¨ç¤º
        mode_info = "è©³ç´°ãƒ¢ãƒ¼ãƒ‰" if args.details else "æ¨™æº–ãƒ¢ãƒ¼ãƒ‰"
        print(f"\nâœ… å‡¦ç†å®Œäº†! ({mode_info})")
        print(f"ğŸ“Š å‡¦ç†ä»¶æ•°: {len(updates)} ä»¶")
        print(f"ğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_path}")

        if len(updates) > 0:
            print(f"\nğŸ“‹ æ›´æ–°ä¸€è¦§:")
            for i, update in enumerate(updates, 1):
                status = "âœ…" if update.get("summary") else "âŒ"
                api_indicator = "ğŸ”" if args.details and update.get("update_id") else ""
                print(f"  {i}. {status}{api_indicator} {update['title'][:60]}...")

        logger.info("å‡¦ç†ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")

    except KeyboardInterrupt:
        logger.info("å‡¦ç†ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        sys.exit(130)
    except Exception as e:
        logger.error(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", exc_info=True)
        sys.exit(1)


if __name__ == "__main__":
    main()
